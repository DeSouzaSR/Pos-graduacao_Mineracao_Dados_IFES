











import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.decomposition import PCA





df = pd.read_csv("../../datasets/evasao_escolar_simulado.csv")  # Substitua pelo caminho correto se necessário
print("Dimensão do dataset:", df.shape)
df.head()





print("Média de evasão percentual por região:")
print(df.groupby("regiao")["evasao_percentual"].mean().round(2))





# Agrupa os dados por região somando os totais de evasão e de matrículas
agrupado = df.groupby("regiao")[["evasao_absoluta", "total_matriculados"]].sum()

# Calcula a taxa percentual de evasão por região de forma ponderada
agrupado["evasao_percentual_corrigida"] = (agrupado["evasao_absoluta"] / agrupado["total_matriculados"]) * 100

# Mostra o resultado final
print(agrupado["evasao_percentual_corrigida"].round(2))






plt.figure(figsize=(8, 4))
sns.histplot(df['evasao_percentual'], bins=20, kde=True)
plt.title("Distribuição da Evasão Percentual")
plt.xlabel("Evasão (%)")
plt.ylabel("Frequência")
plt.grid(True)
plt.show()





df_encoded = pd.get_dummies(df, columns=['regiao', 'localizacao', 'dependencia_adm'], drop_first=True)


df_encoded








features = [
    'infra_biblioteca', 'infra_internet', 'infra_laboratorio',
    'total_matriculados', 'evasao_percentual'
] + [col for col in df_encoded.columns if any(prefix in col for prefix in ['regiao_', 'localizacao_', 'dependencia_adm_'])]

X = df_encoded[features]

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)


X_scaled[0]





scores = []
for k in range(2, 10):
    kmeans = KMeans(n_clusters=k, random_state=42)
    labels = kmeans.fit_predict(X_scaled)
    score = silhouette_score(X_scaled, labels)
    scores.append((k, score))

# Exibe os resultados
for k, s in scores:
    print(f"Silhouette para k={k}: {s:.4f}")

best_k = max(scores, key=lambda x: x[1])[0]
print(f"\nMelhor número de clusters: {best_k}")





kmeans = KMeans(n_clusters=best_k, random_state=42)
df['cluster'] = kmeans.fit_predict(X_scaled)





pca = PCA(n_components=2)
components = pca.fit_transform(X_scaled)
df['pca1'], df['pca2'] = components[:, 0], components[:, 1]

plt.figure(figsize=(8,6))
sns.scatterplot(data=df, x='pca1', y='pca2', hue='cluster', palette='Set2', s=100)
plt.title('Clusters de Escolas com PCA')
plt.xlabel('Componente 1')
plt.ylabel('Componente 2')
plt.grid(True)
plt.legend(title='Cluster')
plt.show()





print("Médias por cluster:")
df.groupby('cluster')[['infra_biblioteca', 'infra_internet', 
                       'infra_laboratorio', 'total_matriculados', 
                       'evasao_percentual']].mean().round(2)


# Visualização detalhada da distribuição para cada cluster com subplots 2x3
variables_to_plot = ['infra_biblioteca', 'infra_internet', 
                     'infra_laboratorio', 'total_matriculados', 
                     'evasao_percentual']

for cluster_id in sorted(df['cluster'].unique()):
    cluster_df = df[df['cluster'] == cluster_id]
    print(f"\nDistribuições para o Cluster {cluster_id}:")
    fig, axes = plt.subplots(2, 3, figsize=(15, 8))
    axes = axes.flatten()
    for i, var in enumerate(variables_to_plot):
        sns.histplot(cluster_df[var], bins=10, kde=False, ax=axes[i])
        axes[i].set_title(f'{var}')
        axes[i].set_xlabel(var)
        axes[i].set_ylabel('Frequência')
        axes[i].grid(True)
    for j in range(len(variables_to_plot), len(axes)):
        fig.delaxes(axes[j])  # Remove subplot vazio se houver
    fig.suptitle(f'Distribuição das Variáveis - Cluster {cluster_id}', fontsize=16)
    plt.tight_layout(rect=[0, 0, 1, 0.95])
    plt.show()






















